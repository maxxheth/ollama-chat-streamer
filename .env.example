# Ollama Chat Streamer - Environment Configuration
# Copy this file to .env and customize the values

# =============================================================================
# OLLAMA CONNECTION
# =============================================================================

# The Ollama host URL
# Use http://localhost:11434 when running with network_mode: host (Linux)
# Use http://host.docker.internal:11434 for Mac/Windows without host networking
OLLAMA_HOST=http://localhost:11434

# The Ollama model to use (e.g., llama3, mistral, codellama, etc.)
OLLAMA_MODEL=llama3

# =============================================================================
# CHAT LOGGING
# =============================================================================

# Path to the chat log file (relative or absolute)
CHAT_LOG_DEST=chat_log.txt

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable experimental features (true/false)
EXPERIMENTAL=false

# Enable intelligent web search - LLM decides when to search (true/false)
# Requires ddgs package (pip install ddgs)
EXPERIMENTAL_WEBSEARCH=false

# =============================================================================
# CONTEXT LOADING
# =============================================================================

# Path to a file or directory to load as context for the LLM
# If a directory, all files matching CONTEXT_GREP extensions will be loaded
CONTEXT_PATH=

# Comma-separated list of file extensions to include when loading from a directory
# Use "*" to include all files
CONTEXT_GREP=txt,log

# =============================================================================
# EXAMPLES
# =============================================================================

# Example 1: Basic setup with local Ollama
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3
# CHAT_LOG_DEST=./logs/chat.log

# Example 2: Enable web search for current information
# EXPERIMENTAL_WEBSEARCH=true

# Example 3: Load project documentation as context
# CONTEXT_PATH=./docs
# CONTEXT_GREP=md,txt

# Example 4: Load a specific file as context
# CONTEXT_PATH=./project_requirements.txt
